import os
import asyncio
import time
import pysrt
import streamlit as st
from pydub import AudioSegment
import edge_tts

# --- C·∫•u h√¨nh FFmpeg ---
# Streamlit s·∫Ω c√†i ƒë·∫∑t FFmpeg t·ª´ file packages.txt
# Ch√∫ng ta kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n th·ªß c√¥ng n·ªØa.

# --- C√°c h√†m x·ª≠ l√Ω c·ªët l√µi (gi·ªØ nguy√™n t·ª´ file c≈©) ---

async def convert_text_to_speech(text, voice, rate, volume, pitch):
    """H√†m chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n ƒë∆°n gi·∫£n."""
    communicate = edge_tts.Communicate(text, voice, rate=rate, volume=volume, pitch=pitch)
    # L∆∞u v√†o m·ªôt file t·∫°m th·ªùi
    temp_file = f"temp_output_{int(time.time())}.mp3"
    await communicate.save(temp_file)
    return temp_file

async def convert_srt_to_timed_speech(srt_content, voice, rate, volume, pitch):
    """H√†m chuy·ªÉn ƒë·ªïi file SRT c√≥ ƒë·ªìng b·ªô h√≥a th·ªùi gian."""
    subs = pysrt.from_string(srt_content)
    final_audio = AudioSegment.silent(duration=0)
    last_end_time_ms = 0
    
    temp_files = [] # ƒê·ªÉ theo d√µi c√°c file t·∫°m

    progress_bar = st.progress(0, text="ƒêang x·ª≠ l√Ω ph·ª• ƒë·ªÅ...")

    for i, sub in enumerate(subs):
        start_time_ms = sub.start.ordinal
        end_time_ms = sub.end.ordinal

        silence_duration = start_time_ms - last_end_time_ms
        if silence_duration > 0:
            final_audio += AudioSegment.silent(duration=silence_duration)

        if not sub.text.strip():
            last_end_time_ms = end_time_ms
            continue

        temp_audio_path = f"temp_{sub.index}_{int(time.time())}.mp3"
        temp_files.append(temp_audio_path)
        try:
            communicate = edge_tts.Communicate(sub.text, voice, rate=rate, volume=volume, pitch=pitch)
            await communicate.save(temp_audio_path)
            
            segment = AudioSegment.from_mp3(temp_audio_path)
            final_audio += segment
            last_end_time_ms = start_time_ms + len(segment)
        except Exception as e:
            st.warning(f"L·ªói ·ªü ph·ª• ƒë·ªÅ {sub.index}: {e}. B·ªè qua...")
            last_end_time_ms = end_time_ms

        # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh
        progress_bar.progress((i + 1) / len(subs), text=f"ƒêang x·ª≠ l√Ω ph·ª• ƒë·ªÅ {i+1}/{len(subs)}")

    # X√≥a c√°c file t·∫°m
    for f in temp_files:
        if os.path.exists(f):
            os.remove(f)

    # Xu·∫•t file cu·ªëi c√πng
    final_output_path = f"timed_output_{int(time.time())}.mp3"
    final_audio.export(final_output_path, format="mp3")
    progress_bar.empty() # X√≥a thanh ti·∫øn tr√¨nh
    return final_output_path

# --- Giao di·ªán ng∆∞·ªùi d√πng Streamlit ---

st.set_page_config(layout="wide")

st.markdown("<h1 style='text-align: center; color: #3498db;'>C√îNG C·ª§ TTS BY L√ù VƒÇN HI·ªÜP</h1>", unsafe_allow_html=True)
st.markdown("---")

# D·ªØ li·ªáu gi·ªçng ƒë·ªçc (t·ª´ file index.html c·ªßa b·∫°n)
all_voices = [
    { "ShortName": "vi-VN-HoaiMyNeural", "FriendlyName": "HoaiMy", "Locale": "Vietnamese", "Gender": "Female" },
    { "ShortName": "vi-VN-NamMinhNeural", "FriendlyName": "NamMinh", "Locale": "Vietnamese", "Gender": "Male" },
    { "ShortName": "ko-KR-BongJinNeural", "FriendlyName": "BongJin", "Locale": "Korean", "Gender": "Male" },
    { "ShortName": "ko-KR-GookMinNeural", "FriendlyName": "GookMin", "Locale": "Korean", "Gender": "Male" },
    { "ShortName": "ko-KR-InJoonNeural", "FriendlyName": "InJoon", "Locale": "Korean", "Gender": "Male" },
    { "ShortName": "ko-KR-JiMinNeural", "FriendlyName": "JiMin", "Locale": "Korean", "Gender": "Female" },
    { "ShortName": "ko-KR-SeoHyeonNeural", "FriendlyName": "SeoHyeon", "Locale": "Korean", "Gender": "Female" },
    { "ShortName": "ko-KR-SunHiNeural", "FriendlyName": "SunHi", "Locale": "Korean", "Gender": "Female" },
    { "ShortName": "ja-JP-AoiNeural", "FriendlyName": "Aoi", "Locale": "Japanese", "Gender": "Female" },
    { "ShortName": "ja-JP-DaichiNeural", "FriendlyName": "Daichi", "Locale": "Japanese", "Gender": "Male" },
    { "ShortName": "ja-JP-KeitaNeural", "FriendlyName": "Keita", "Locale": "Japanese", "Gender": "Male" },
    { "ShortName": "ja-JP-NanamiNeural", "FriendlyName": "Nanami", "Locale": "Japanese", "Gender": "Female" },
    { "ShortName": "en-US-BrandonNeural", "FriendlyName": "Brandon", "Locale": "English (US)", "Gender": "Male" },
    { "ShortName": "en-US-ChristopherNeural", "FriendlyName": "Christopher", "Locale": "English (US)", "Gender": "Male" },
    { "ShortName": "en-US-CoraNeural", "FriendlyName": "Cora", "Locale": "English (US)", "Gender": "Female" },
    # Th√™m c√°c gi·ªçng ƒë·ªçc kh√°c n·∫øu c·∫ßn
]

# Chia layout th√†nh 2 c·ªôt
col1, col2 = st.columns([1, 2])

with col1:
    st.header("B·∫£ng ƒëi·ªÅu khi·ªÉn ‚öôÔ∏è")
    
    # T√¨m ki·∫øm v√† ch·ªçn gi·ªçng ƒë·ªçc
    search_term = st.text_input("T√¨m ki·∫øm gi·ªçng ƒë·ªçc (e.g., vi, en-US, female...)", "")
    
    filtered_voices = [
        v for v in all_voices if 
        search_term.lower() in v['FriendlyName'].lower() or 
        search_term.lower() in v['Locale'].lower() or
        search_term.lower() in v['Gender'].lower()
    ]
    
    voice_options = {f"{v['FriendlyName']} ({v['Locale']}, {v['Gender']})": v['ShortName'] for v in filtered_voices}
    
    selected_voice_display = st.selectbox(
        "Ch·ªçn gi·ªçng ƒë·ªçc", 
        options=list(voice_options.keys()),
        index=0 # M·∫∑c ƒë·ªãnh ch·ªçn gi·ªçng ƒë·∫ßu ti√™n
    )
    voice_select = voice_options[selected_voice_display]
    st.info(f"ƒê√£ t√¨m th·∫•y {len(filtered_voices)}/{len(all_voices)} gi·ªçng ƒë·ªçc.")

    # C√°c thanh tr∆∞·ª£t
    rate_val = st.slider("T·ªëc ƒë·ªô", -100, 100, 0)
    volume_val = st.slider("√Çm l∆∞·ª£ng", -100, 100, 0)
    pitch_val = st.slider("Cao ƒë·ªô (Hz)", -50, 50, 0)
    
    # ƒê·ªãnh d·∫°ng l·∫°i gi√° tr·ªã cho edge-tts
    rate = f"{'+' if rate_val >= 0 else ''}{rate_val}%"
    volume = f"{'+' if volume_val >= 0 else ''}{volume_val}%"
    pitch = f"{'+' if pitch_val >= 0 else ''}{pitch_val}Hz"

with col2:
    st.header("N·ªôi dung & K·∫øt qu·∫£ üìù")

    uploaded_file = st.file_uploader("T·∫£i l√™n file .txt ho·∫∑c .srt", type=['txt', 'srt'])
    
    # Checkbox ƒë·ªìng b·ªô SRT ch·ªâ hi·ªÉn th·ªã khi c√≥ file .srt ƒë∆∞·ª£c t·∫£i l√™n
    is_srt_timed = False
    if uploaded_file and uploaded_file.name.lower().endswith('.srt'):
        is_srt_timed = st.checkbox("ƒê·ªìng b·ªô h√≥a th·ªùi gian file SRT", value=True)

    st.divider()

    text_input = st.text_area("Ho·∫∑c nh·∫≠p vƒÉn b·∫£n v√†o ƒë√¢y...", height=250, 
        value=uploaded_file.read().decode('utf-8') if uploaded_file else ""
    )
    
    if st.button("Chuy·ªÉn ƒë·ªïi th√†nh gi·ªçng n√≥i", use_container_width=True, type="primary"):
        if not text_input.strip() and not uploaded_file:
            st.error("Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ho·∫∑c t·∫£i l√™n m·ªôt file.")
        else:
            final_text = text_input
            
            with st.spinner('ƒêang x·ª≠ l√Ω, vui l√≤ng ch·ªù...'):
                try:
                    output_file = None
                    # X·ª≠ l√Ω SRT c√≥ ƒë·ªìng b·ªô
                    if uploaded_file and uploaded_file.name.lower().endswith('.srt') and is_srt_timed:
                         srt_content = final_text
                         output_file = asyncio.run(convert_srt_to_timed_speech(srt_content, voice_select, rate, volume, pitch))
                    # X·ª≠ l√Ω vƒÉn b·∫£n th∆∞·ªùng ho·∫∑c SRT kh√¥ng ƒë·ªìng b·ªô
                    else:
                        output_file = asyncio.run(convert_text_to_speech(final_text, voice_select, rate, volume, pitch))

                    st.success("Ho√†n t·∫•t! ‚úÖ")
                    
                    # Hi·ªÉn th·ªã tr√¨nh ph√°t v√† n√∫t t·∫£i xu·ªëng
                    audio_file = open(output_file, 'rb')
                    audio_bytes = audio_file.read()
                    st.audio(audio_bytes, format='audio/mpeg')
                    
                    st.download_button(
                        label="T·∫£i xu·ªëng file MP3",
                        data=audio_bytes,
                        file_name=os.path.basename(output_file),
                        mime='audio/mpeg'
                    )
                    
                    # D·ªçn d·∫πp file ƒë√£ t·∫°o
                    if os.path.exists(output_file):
                        os.remove(output_file)

                except Exception as e:
                    st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")